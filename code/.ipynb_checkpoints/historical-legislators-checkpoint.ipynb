{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "import urllib.request as requests\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory\n",
    "os.chdir(\"/Users/mathiasrask/Desktop/kandidat/E2020/Advanced-Quantitative-Methods/\")\n",
    "\n",
    "# define url\n",
    "url = \"https://theunitedstates.io/congress-legislators/\"\n",
    "\n",
    "# define name of files to be parsed\n",
    "social_media = 'legislators-social-media.yaml'\n",
    "historical   = 'legislators-historical.yaml'\n",
    "current      = 'legislators-current.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump file in YAML-format \n",
    "#soup = bs(content)\n",
    "#with open('social-media-accounts/legislators-historical.yaml', 'w') as file:\n",
    "#    documents = yaml.dump(soup, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml(url):\n",
    "    url = requests.urlopen(url)               # connect to url\n",
    "    content = url.read().decode('utf-8')      # read and decode to UTF-8 format \n",
    "    return content\n",
    "\n",
    "def clean_yaml(string, file:str):\n",
    "    content = string.split('\\n')\n",
    "    content = [x.lstrip(\"' '|>-\") for x in content]\n",
    "    \n",
    "    if file == 'social-media':\n",
    "        content = content[18:]\n",
    "    if file == 'legislators':\n",
    "        content[0] = re.sub('[ b\\'-]', \"\", content[0])\n",
    "    return content\n",
    "\n",
    "def split_list(match:list, string, within_legislator=False):\n",
    "    def match_function():\n",
    "        matches = [re.match(match, x) for x in string]\n",
    "        matches = [x is not None for x in matches]    \n",
    "        return np.cumsum(matches).tolist()\n",
    "    \n",
    "    indices = match_function()\n",
    "    \n",
    "    def split_indices():\n",
    "        results = []\n",
    "        for idx, val in enumerate(indices):\n",
    "            if idx == 0:\n",
    "                results.append([val])\n",
    "                continue\n",
    "            if val > indices[idx - 1]:\n",
    "                results.append([val])\n",
    "            else:\n",
    "                results[-1].append(val)\n",
    "        return np.cumsum([len(x) for x in results]).tolist()\n",
    "    \n",
    "    #if within_legislator == False:\n",
    "    #    indices = split_indices()\n",
    "    #    indices = np.cumsum([len(x) for x in indices]).tolist()\n",
    "    #if within_legislator == True:\n",
    "    #    indices = split_indices()\n",
    "    #    indices = np.cumsum([len(x) for x in indices]).tolist()\n",
    "    indices = split_indices()\n",
    "    def decomposition():\n",
    "        decomposed_list = []\n",
    "        for idx, val in enumerate(indices):\n",
    "            if idx == 0:\n",
    "                decomposed_list.append(string[0:val])\n",
    "            else:\n",
    "                current  = indices[idx]\n",
    "                previous = indices[idx-1] \n",
    "                decomposed_list.append(string[previous:current])\n",
    "        return decomposed_list\n",
    "    \n",
    "    final = decomposition()\n",
    "    \n",
    "    # remove potential empty elements\n",
    "    final = [[x for x in l if x] for l in final]\n",
    "    \n",
    "    return final\n",
    "\n",
    "def get_index_positions(list_object, element):\n",
    "    \"\"\"\n",
    "    Returns the indexes of all occurrences of an element in\n",
    "    a list.\n",
    "    \"\"\"  \n",
    "    index_pos_list = []\n",
    "    index_pos = 0\n",
    "    while True:\n",
    "        try:\n",
    "            # Search for item in list from indexPos to the end of list\n",
    "            index_pos = list_object.index(element, index_pos)\n",
    "            # Add the index position in list\n",
    "            index_pos_list.append(index_pos)\n",
    "            index_pos += 1\n",
    "        except ValueError as e:\n",
    "            break\n",
    "    return index_pos_list\n",
    "\n",
    "def del_list_numpy(l, id_to_del):\n",
    "    \"\"\"\n",
    "    Delete indicies from list using numpy's delete-function.\n",
    "    \"\"\"\n",
    "    arr = np.array(l)\n",
    "    return list(np.delete(arr, id_to_del))\n",
    "\n",
    "\n",
    "def delete_party_affiliations(list_object):\n",
    "    for idx, val in enumerate(list_object):\n",
    "        \n",
    "        party_aff = [re.match('party_affiliations:',x) is not None for x in list_object[idx]['terms:']]\n",
    "        type_     = [re.match('type:',x) is not None for x in list_object[idx]['terms:']]\n",
    "        \n",
    "        type_indices      = get_index_positions(type_, True)\n",
    "        party_aff_indices = get_index_positions(party_aff, True)\n",
    "        \n",
    "        distances = []\n",
    "        indices = []\n",
    "        \n",
    "        for idx1, val1 in enumerate(party_aff_indices):\n",
    "            temp = []\n",
    "            for idx2, val2 in enumerate(type_indices):\n",
    "                temp.append(val2 - val1)\n",
    "            \n",
    "            if max(temp) > 0:\n",
    "                index = temp.index(min([i for i in temp if i > 0]))\n",
    "                indices = indices + list(range(val1, type_indices[index]))\n",
    "                distances.append(index)\n",
    "            \n",
    "            if max(temp) < 0:\n",
    "                indices = indices + list(range(max(party_aff_indices), len(list_object[idx]['terms:'])))\n",
    "        \n",
    "        list_object[idx]['terms:'] = del_list_numpy(list_object[idx]['terms:'], indices)    \n",
    "    \n",
    "    return list_object\n",
    "\n",
    "def clean_bio(list_object, element:str):    \n",
    "    \"\"\"\n",
    "    Function to clean-up fec-numbers and id to biographical information\n",
    "    \"\"\"\n",
    "    for idx, val in enumerate(list_object):\n",
    "        index = [re.match(element,x) for x in val]\n",
    "\n",
    "        if np.sum([x!=None for x in index]) > 0:\n",
    "            element_index = [x!=None for x in index].index(True)\n",
    "            if element == 'fec:':\n",
    "                matches = [re.match('[A-Z0-9]{9}', val[i]) for i in range(element_index+0, element_index+4)]\n",
    "\n",
    "            if element == 'bioguide_previous:':\n",
    "                matches = [re.match('[A-Z0-9]{7}', val[i]) for i in range(element_index+0, element_index+4)]\n",
    "\n",
    "            index_match = get_index_positions([x!=None for x in matches], True)\n",
    "\n",
    "            N_matches = np.sum([x is not None for x in matches])\n",
    "\n",
    "            if element == 'fec:':\n",
    "                element_numbers = [matches[index_match[i]].string for i in range(N_matches)]\n",
    "                element_numbers = '|'.join(element_numbers)\n",
    "                list_object[idx][element_index] = list_object[idx][element_index] + ' ' + element_numbers\n",
    "\n",
    "            if element == 'bioguide_previous:':\n",
    "                for i in range(N_matches):\n",
    "                    list_object[idx][element_index] = list_object[idx][element_index] + ' ' + matches[index_match[i]].string\n",
    "\n",
    "            list_object[idx] = del_list_numpy(list_object[idx], [i+element_index for i in index_match])\n",
    "    return list_object\n",
    "\n",
    "\n",
    "def get_row_indices(list_object, match:str):\n",
    "    return np.cumsum([re.match(match,x[0]) is not None for x in list_object])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to move bioguide into the second element of the list\n",
    "def clean_bioguide():\n",
    "    # For-loop to make sure that bioguide is at top\n",
    "    #for idx, val in enumerate(between_legislator):\n",
    "    matches = [re.match('bioguide: (.*)', x) for x in val]\n",
    "    boolean = [x is not None for x in matches]\n",
    "\n",
    "    bioguide = [x.string for x in matches if x is not None][0]\n",
    "    bio_position = get_index_positions(boolean, True)[0]\n",
    "\n",
    "    if bio_position != 1:\n",
    "        replace_element = between_legislator[idx][1]\n",
    "        between_legislator[idx][1] = bioguide\n",
    "        between_legislator[idx][bio_position] = replace_element\n",
    "    return\n",
    "\n",
    "# Function to assure that \"name:\" only figures once\n",
    "def clean_family():\n",
    "    matches = [re.match(\"name:\", x) for x in val]\n",
    "    indices = get_index_positions([x!=None for x in matches], True)\n",
    "\n",
    "    # get indices for the actual name element\n",
    "    name_indices = get_index_positions([x.group()==x.string for x in matches if x is not None], False)\n",
    "\n",
    "    # keep only indices to be changed\n",
    "    indices = [indices[x] for x in name_indices]\n",
    "\n",
    "    # construct pairs of the name-title and the name of the fam. member\n",
    "    match_pairs = [re.match('(.*): (.*)', between_legislator[idx][x]).groups() for x in indices]\n",
    "    \n",
    "    # replace family names\n",
    "    for i,v in enumerate(indices):\n",
    "        between_legislator[idx][v] = f\"{match_pairs[i][0]}_fam: {match_pairs[i][1]}\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical Legislators\n",
    "\n",
    "In this section, I prepare the data for historical legislators, that is legislators not in the current US Congress (116th). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read yaml-file for historical data\n",
    "content = read_yaml(url=f\"{url}{historical}\")\n",
    "content = clean_yaml(content, file='legislators')\n",
    "\n",
    "# Split list into sub-lists for each legislator\n",
    "between_legislator = split_list(match=\"id:\", string=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure bioguide is on top and clean the family section\n",
    "for idx, val in enumerate(between_legislator):\n",
    "    clean_bioguide()\n",
    "    clean_family()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete contact information from list\n",
    "delete_info = [[re.match('address:|phone:|fax:|contact_form:|office:|other_names:|rss_url:',x) for x in l] for l in between_legislator]\n",
    "boolean = [[x is None for x in c] for c in delete_info]\n",
    "delete_indices = [get_index_positions(x, False) for x in boolean]\n",
    "between_legislator = [del_list_numpy(between_legislator[idx], delete_indices[idx]) for idx in range(len(between_legislator))]\n",
    "\n",
    "# Clean up fec and bioguide \n",
    "between_legislator = clean_bio(between_legislator, element='fec:')\n",
    "between_legislator = clean_bio(between_legislator, element='bioguide_previous:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split list into sub-lists for each legislator\n",
    "#between_legislator = split_list(match=\"id:\", string=content)\n",
    "#\n",
    "# Delete contact information for each legislator\n",
    "#contact = [[re.match('address:|phone:|fax:|contact_form:|office:|other_names:|rss_url:|family:|relation:',x) for x in l] for l in between_legislator]\n",
    "#subset_index = [[x is None for x in c] for c in contact]\n",
    "#contact = [[x.string for x in c if x is not None] for c in contact]\n",
    "#delete_indices = [get_index_positions(x, False) for x in subset_index]\n",
    "#between_legislator = [del_list_numpy(between_legislator[idx], delete_indices[idx]) for idx in range(len(between_legislator))]\n",
    "#\n",
    "# Clean up fec and bioguide\n",
    "#between_legislator = clean_bio(between_legislator, element='fec:')\n",
    "#between_legislator = clean_bio(between_legislator, element='bioguide_previous:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to delete all family names\n",
    "#matches = [re.match(\"name:\", x) for x in between_legislator]\n",
    "#indices = get_index_positions([x!=None for x in matches], True)\n",
    "#name_matches = get_index_positions([matches[x].group()=='name:' for x in indices], True)\n",
    "#name_indices = [indices[x] for x in name_matches]\n",
    "#change_name_index = [x for x in name_indices if matches[x].group()!=matches[x].string]\n",
    "#del_list_numpy(between_legislator, change_name_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a list for each type of information for each legislator.\n",
    "# I delete party affiliations within the 'terms'-list to avoid complications.\n",
    "#within_legislator = [split_list(match=\"id:|name:|bio:|terms:|leadership_roles:|family:\", string=x) for x in between_legislator]\n",
    "within_legislator = [split_list(match=\"id:|name:|bio:|terms:|leadership_roles:|family:\", string=x) for x in between_legislator]\n",
    "within_legislator = [{x[0]:x[1:] for x in l} for l in within_legislator]\n",
    "within_legislator = delete_party_affiliations(within_legislator)\n",
    "\n",
    "# Constuct column-row pairs for each legislator\n",
    "for idx0, val0 in enumerate(within_legislator):\n",
    "    for idx1, val1 in enumerate(val0):\n",
    "        within_legislator[idx0][val1] = [re.match('(.*): (.*)', x).groups() for x in within_legislator[idx0][val1]] \n",
    "        \n",
    "\n",
    "for idx in range(len(within_legislator)):\n",
    "    boolean_end = [re.match('end', x) is not None for x,y in within_legislator[idx]['name:']]\n",
    "    if sum(boolean_end) > 0:\n",
    "        end_position = get_index_positions(boolean_end, True)[0]\n",
    "        del within_legislator[idx]['name:'][end_position]\n",
    "\n",
    "for idx in range(len(within_legislator)):\n",
    "    boolean_middle = [re.match('~', y) is not None for x,y in within_legislator[idx]['name:']]\n",
    "    if sum(boolean_middle) > 0:\n",
    "        middle_position = get_index_positions(boolean_middle, True)[0]\n",
    "        del within_legislator[idx]['name:'][middle_position]\n",
    "\n",
    "for idx, val in enumerate(within_legislator):\n",
    "    last_positions = get_index_positions([re.match('last', x) is not None for x,y in within_legislator[idx]['name:']],True)\n",
    "    if len(last_positions) > 1:\n",
    "        max_last = max(last_positions)\n",
    "        del within_legislator[idx]['name:'][max_last]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n"
     ]
    }
   ],
   "source": [
    "# Loop through each legislator and create a dataframe for each of them \n",
    "df_leader_list = []\n",
    "df_family_list = []\n",
    "df_list   = []\n",
    "\n",
    "for idx0, val0 in enumerate(within_legislator):\n",
    "    if idx0%500 == 0:\n",
    "        print(idx0)\n",
    "    for idx1, val1 in enumerate(val0):\n",
    "        subset = within_legislator[idx0][val1]\n",
    "        \n",
    "        if val1 == 'id:':\n",
    "            row_index = get_row_indices(subset, match='bioguide')\n",
    "        if val1 == 'name:':\n",
    "            row_index = get_row_indices(subset, match='first')\n",
    "        if val1 == 'bio:':\n",
    "            row_index = get_row_indices(subset, match='birthday')    \n",
    "        if val1 == 'terms:':\n",
    "            row_index = get_row_indices(subset, match='type')\n",
    "        \n",
    "        if val1 == 'leadership_roles:':\n",
    "            row_index = get_row_indices(subset, match='title')\n",
    "            temp = pd.DataFrame()\n",
    "            for idx2, val2 in enumerate(row_index):\n",
    "                temp.loc[val2, within_legislator[idx0]['id:'][0][0]] = within_legislator[idx0]['id:'][0][1]\n",
    "                temp.loc[val2, subset[idx2][0]] = subset[idx2][1]\n",
    "            df_leader_list.append(temp)\n",
    "        \n",
    "        elif val1 == 'family:':\n",
    "            row_index = get_row_indices(subset, match='name_fam')\n",
    "            temp = pd.DataFrame()\n",
    "            for idx2, val2 in enumerate(row_index):\n",
    "                temp.loc[val2, within_legislator[idx0]['id:'][0][0]] = within_legislator[idx0]['id:'][0][1]\n",
    "                temp.loc[val2, subset[idx2][0]] = subset[idx2][1]\n",
    "            df_family_list.append(temp)\n",
    "        \n",
    "        else:\n",
    "            if val1 == 'id:':\n",
    "                temp = pd.DataFrame()\n",
    "                for idx2, val2 in enumerate(row_index):\n",
    "                    temp.loc[val2, subset[idx2][0]] = subset[idx2][1]\n",
    "                df = temp\n",
    "            else:\n",
    "                temp = pd.DataFrame()\n",
    "                for idx2, val2 in enumerate(row_index):\n",
    "                    temp.loc[val2, within_legislator[idx0]['id:'][0][0]] = within_legislator[idx0]['id:'][0][1]\n",
    "                    temp.loc[val2, subset[idx2][0]] = subset[idx2][1]\n",
    "                df = df.merge(temp, on=['bioguide'])\n",
    "    \n",
    "    gender_match   = [re.match('gender',  x) is not None for x in list(df.columns)]\n",
    "    birthday_match = [re.match('birthday',x) is not None for x in list(df.columns)]\n",
    "    if sum(gender_match) == 1:\n",
    "        df['gender']   = df['gender'].fillna(method='ffill')\n",
    "    if sum(birthday_match) == 1:\n",
    "        df['birthday'] = df['birthday'].fillna(method='bfill')\n",
    "    \n",
    "    if (sum(gender_match) == 1) or (sum(birthday_match)==1):\n",
    "        df = df[df.duplicated()]\n",
    "    \n",
    "    # append df to df-list\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df_family = pd.concat(df_family_list, ignore_index=True)\n",
    "df_leader = pd.concat(df_leader_list, ignore_index=True)\n",
    "\n",
    "df = df.drop(columns=['how'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df.to_csv('data/historical-legislators.csv', index=False,sep=',')\n",
    "df_family.to_csv('data/historical-legislators-family.csv', index=False,sep=',')\n",
    "df_leader.to_csv('data/historical-legislators-leader.csv', index=False,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Legislators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read yaml-file for historical data\n",
    "content = read_yaml(url=f\"{url}{current}\")\n",
    "content = clean_yaml(content, file='legislators')\n",
    "\n",
    "# Split list into sub-lists for each legislator\n",
    "between_legislator = split_list(match=\"id:\", string=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure bioguide is on top and clean the family section\n",
    "for idx, val in enumerate(between_legislator):\n",
    "    clean_bioguide()\n",
    "    clean_family()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete contact information from list\n",
    "delete_info = [[re.match('address:|phone:|fax:|contact_form:|office:|other_names:|rss_url:',x) for x in l] for l in between_legislator]\n",
    "boolean = [[x is None for x in c] for c in delete_info]\n",
    "delete_indices = [get_index_positions(x, False) for x in boolean]\n",
    "between_legislator = [del_list_numpy(between_legislator[idx], delete_indices[idx]) for idx in range(len(between_legislator))]\n",
    "\n",
    "# Clean up fec and bioguide \n",
    "between_legislator = clean_bio(between_legislator, element='fec:')\n",
    "between_legislator = clean_bio(between_legislator, element='bioguide_previous:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a list for each type of information for each legislator.\n",
    "# I delete party affiliations within the 'terms'-list to avoid complications.\n",
    "#within_legislator = [split_list(match=\"id:|name:|bio:|terms:|leadership_roles:|family:\", string=x) for x in between_legislator]\n",
    "within_legislator = [split_list(match=\"id:|name:|bio:|terms:|leadership_roles:|family:\", string=x) for x in between_legislator]\n",
    "within_legislator = [{x[0]:x[1:] for x in l} for l in within_legislator]\n",
    "within_legislator = delete_party_affiliations(within_legislator)\n",
    "\n",
    "# Constuct column-row pairs for each legislator\n",
    "for idx0, val0 in enumerate(within_legislator):\n",
    "    for idx1, val1 in enumerate(val0):\n",
    "        within_legislator[idx0][val1] = [re.match('(.*): (.*)', x).groups() for x in within_legislator[idx0][val1]] \n",
    "    \n",
    "for idx in range(len(within_legislator)):\n",
    "    boolean_end = [re.match('end', x) is not None for x,y in within_legislator[idx]['name:']]\n",
    "    if sum(boolean_end) > 0:\n",
    "        end_position = get_index_positions(boolean_end, True)[0]\n",
    "        del within_legislator[idx]['name:'][end_position]\n",
    "\n",
    "for idx in range(len(within_legislator)):\n",
    "    boolean_middle = [re.match('~', y) is not None for x,y in within_legislator[idx]['name:']]\n",
    "    if sum(boolean_middle) > 0:\n",
    "        middle_position = get_index_positions(boolean_middle, True)[0]\n",
    "        del within_legislator[idx]['name:'][middle_position]\n",
    "\n",
    "for idx, val in enumerate(within_legislator):\n",
    "    last_positions = get_index_positions([re.match('last', x) is not None for x,y in within_legislator[idx]['name:']],True)\n",
    "    if len(last_positions) > 1:\n",
    "        max_last = max(last_positions)\n",
    "        del within_legislator[idx]['name:'][max_last]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# Loop through each legislator and create a dataframe for each of them \n",
    "df_leader_list = []\n",
    "df_family_list = []\n",
    "df_list   = []\n",
    "\n",
    "for idx0, val0 in enumerate(within_legislator):\n",
    "    if idx0%100 == 0:\n",
    "        print(idx0)\n",
    "    for idx1, val1 in enumerate(val0):\n",
    "        subset = within_legislator[idx0][val1]\n",
    "        \n",
    "        if val1 == 'id:':\n",
    "            row_index = get_row_indices(subset, match='bioguide')\n",
    "        if val1 == 'name:':\n",
    "            row_index = get_row_indices(subset, match='first')\n",
    "        if val1 == 'bio:':\n",
    "            row_index = get_row_indices(subset, match='birthday')    \n",
    "        if val1 == 'terms:':\n",
    "            row_index = get_row_indices(subset, match='type')\n",
    "        \n",
    "        if val1 == 'leadership_roles:':\n",
    "            row_index = get_row_indices(subset, match='title')\n",
    "            temp = pd.DataFrame()\n",
    "            for idx2, val2 in enumerate(row_index):\n",
    "                temp.loc[val2, within_legislator[idx0]['id:'][0][0]] = within_legislator[idx0]['id:'][0][1]\n",
    "                temp.loc[val2, subset[idx2][0]] = subset[idx2][1]\n",
    "            df_leader_list.append(temp)\n",
    "        \n",
    "        elif val1 == 'family:':\n",
    "            row_index = get_row_indices(subset, match='name_fam')\n",
    "            temp = pd.DataFrame()\n",
    "            for idx2, val2 in enumerate(row_index):\n",
    "                temp.loc[val2, within_legislator[idx0]['id:'][0][0]] = within_legislator[idx0]['id:'][0][1]\n",
    "                temp.loc[val2, subset[idx2][0]] = subset[idx2][1]\n",
    "            df_family_list.append(temp)\n",
    "        \n",
    "        else:\n",
    "            if val1 == 'id:':\n",
    "                temp = pd.DataFrame()\n",
    "                for idx2, val2 in enumerate(row_index):\n",
    "                    temp.loc[val2, subset[idx2][0]] = subset[idx2][1]\n",
    "                df = temp\n",
    "            else:\n",
    "                temp = pd.DataFrame()\n",
    "                for idx2, val2 in enumerate(row_index):\n",
    "                    temp.loc[val2, within_legislator[idx0]['id:'][0][0]] = within_legislator[idx0]['id:'][0][1]\n",
    "                    temp.loc[val2, subset[idx2][0]] = subset[idx2][1]\n",
    "                df = df.merge(temp, on=['bioguide'])\n",
    "    \n",
    "    df['gender']   = df['gender'].fillna(method='ffill')\n",
    "    df['birthday'] = df['birthday'].fillna(method='bfill')\n",
    "    df = df[df.duplicated()]\n",
    "    \n",
    "    # append df to df-list\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df_family = pd.concat(df_family_list, ignore_index=True)\n",
    "df_leader = pd.concat(df_leader_list, ignore_index=True)\n",
    "\n",
    "df = df.drop(columns=['how'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df.to_csv('data/current-legislators.csv', index=False,sep=',')\n",
    "df_family.to_csv('data/current-legislators-family.csv', index=False,sep=',')\n",
    "df_leader.to_csv('data/current-legislators-leader.csv', index=False,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read yaml-file for historical data\n",
    "content = read_yaml(url=f\"{url}{social_media}\")\n",
    "content = clean_yaml(content, file='legislators')\n",
    "\n",
    "# Split list into sub-lists for each legislator\n",
    "between_legislator = split_list(match=\"id:\", string=content)\n",
    "\n",
    "# delete first element of list\n",
    "del between_legislator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val in enumerate(between_legislator):\n",
    "    clean_bioguide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up fec and bioguide if needed to \n",
    "between_legislator = clean_bio(between_legislator, element='fec:')\n",
    "between_legislator = clean_bio(between_legislator, element='bioguide_previous:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_legislator = [split_list(match=\"id:|social:\", string=x) for x in between_legislator]\n",
    "within_legislator = [{x[0]:x[1:] for x in l} for l in within_legislator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx0, val0 in enumerate(within_legislator):\n",
    "    for idx1, val1 in enumerate(val0):\n",
    "        within_legislator[idx0][val1] = [re.match('(.*): (.*)', x).groups() for x in within_legislator[idx0][val1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for idx0, val0 in enumerate(within_legislator):\n",
    "    for idx1, val1 in enumerate(val0):\n",
    "            temp = pd.DataFrame(within_legislator[idx0][val1]).T\n",
    "            temp.columns = temp.iloc[0]\n",
    "            temp = temp[1:]\n",
    "            within_legislator[idx0][val1] = temp\n",
    "    df_list.append(within_legislator[idx0]['id:'].join(within_legislator[idx0]['social:']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df.to_csv('data/social-media.csv', index=False,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = {\"lis\": str, \"thomas\":str ,\"ballotpedia\":str ,\"cspan\": str,\n",
    "            \"official_full\": str, \"opensecrets\": str, \"url\":str,\n",
    "            \"fec\": str, \"state_rank\": str, \"district\":str, \n",
    "            \"house_history\":str, \"votesmart\":str, \"govtrack\":str}\n",
    "\n",
    "df_historical = pd.read_csv('data/historical-legislators.csv', dtype=datatype)\n",
    "df_current    = pd.read_csv('data/current-legislators.csv',  dtype=datatype)\n",
    "\n",
    "datatype = {\"thomas\":str, \"govtrack\":str, \"twitter_id\":str,\n",
    "           'instagram_id':str, 'youtube_id':str, 'youtube':str,\n",
    "           'facebook':str, 'twitter':str, 'instagram': str}\n",
    "df_some       = pd.read_csv('data/social-media.csv', dtype=datatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df_historical, df_current))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_some, df, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rep</td>\n",
       "      <td>'2015-01-06'</td>\n",
       "      <td>'2017-01-03'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rep</td>\n",
       "      <td>'2017-01-03'</td>\n",
       "      <td>'2019-01-03'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rep</td>\n",
       "      <td>'2019-01-03'</td>\n",
       "      <td>'2021-01-03'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type         start           end\n",
       "0  rep  '2015-01-06'  '2017-01-03'\n",
       "1  rep  '2017-01-03'  '2019-01-03'\n",
       "2  rep  '2019-01-03'  '2021-01-03'"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_current[df_current['bioguide']=='G000061']\n",
    "df[df['bioguide']=='R000600'].loc[:,['type','start','end']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioguide</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y000064</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bioguide  end\n",
       "3  Y000064  NaN"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3:3,['bioguide', 'end']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioguide</th>\n",
       "      <th>thomas</th>\n",
       "      <th>govtrack</th>\n",
       "      <th>twitter</th>\n",
       "      <th>facebook</th>\n",
       "      <th>youtube_id</th>\n",
       "      <th>twitter_id</th>\n",
       "      <th>youtube</th>\n",
       "      <th>instagram</th>\n",
       "      <th>instagram_id</th>\n",
       "      <th>...</th>\n",
       "      <th>lis</th>\n",
       "      <th>ballotpedia</th>\n",
       "      <th>official_full</th>\n",
       "      <th>opensecrets</th>\n",
       "      <th>url</th>\n",
       "      <th>fec</th>\n",
       "      <th>maplight</th>\n",
       "      <th>state_rank</th>\n",
       "      <th>caucus</th>\n",
       "      <th>end-type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y000064</td>\n",
       "      <td>'02019'</td>\n",
       "      <td>412428</td>\n",
       "      <td>SenToddYoung</td>\n",
       "      <td>SenatorToddYoung</td>\n",
       "      <td>UCuknj4PGn91gHDNAfboZEgQ</td>\n",
       "      <td>234128524</td>\n",
       "      <td>RepToddYoung</td>\n",
       "      <td>sentoddyoung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Y000062</td>\n",
       "      <td>'01853'</td>\n",
       "      <td>412211</td>\n",
       "      <td>RepJohnYarmuth</td>\n",
       "      <td>'214258646163'</td>\n",
       "      <td>UCy5KW4yrEfEiyZRX45Eoxkg</td>\n",
       "      <td>384913290</td>\n",
       "      <td>RepJohnYarmuth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Y000033</td>\n",
       "      <td>'01256'</td>\n",
       "      <td>400440</td>\n",
       "      <td>RepDonYoung</td>\n",
       "      <td>RepDonYoung</td>\n",
       "      <td>UCg5ZIR5-82EbJiNeI1bqT-A</td>\n",
       "      <td>37007274</td>\n",
       "      <td>RepDonYoung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>W000809</td>\n",
       "      <td>'01991'</td>\n",
       "      <td>412402</td>\n",
       "      <td>Rep_SteveWomack</td>\n",
       "      <td>RepSteveWomack</td>\n",
       "      <td>UCXJbUDLYX-wGIhRuN66hqZw</td>\n",
       "      <td>234469322</td>\n",
       "      <td>CongressmanWomack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>W000808</td>\n",
       "      <td>'02004'</td>\n",
       "      <td>412412</td>\n",
       "      <td>RepWilson</td>\n",
       "      <td>RepWilson</td>\n",
       "      <td>UCP5QBhng_lHv-vJgE_h7lpA</td>\n",
       "      <td>234014087</td>\n",
       "      <td>repfredericawilson</td>\n",
       "      <td>repwilson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>O000173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ilhan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1082334352711790593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>C001055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RepEdCase</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1081350574589833221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>H001089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SenHawleyPress</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1080960924687704064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>V000133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CongressmanJVD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1083469084648505344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>M000687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>407672</td>\n",
       "      <td>RepKweisiMfume</td>\n",
       "      <td>RepKweisiMfume</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1276209702322438148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bioguide   thomas govtrack          twitter          facebook  \\\n",
       "3    Y000064  '02019'   412428     SenToddYoung  SenatorToddYoung   \n",
       "6    Y000062  '01853'   412211   RepJohnYarmuth    '214258646163'   \n",
       "7    Y000033  '01256'   400440      RepDonYoung       RepDonYoung   \n",
       "8    W000809  '01991'   412402  Rep_SteveWomack    RepSteveWomack   \n",
       "9    W000808  '02004'   412412        RepWilson         RepWilson   \n",
       "..       ...      ...      ...              ...               ...   \n",
       "913  O000173      NaN      NaN            Ilhan               NaN   \n",
       "914  C001055      NaN      NaN        RepEdCase               NaN   \n",
       "915  H001089      NaN      NaN   SenHawleyPress               NaN   \n",
       "916  V000133      NaN      NaN   CongressmanJVD               NaN   \n",
       "922  M000687      NaN   407672   RepKweisiMfume    RepKweisiMfume   \n",
       "\n",
       "                   youtube_id           twitter_id             youtube  \\\n",
       "3    UCuknj4PGn91gHDNAfboZEgQ            234128524        RepToddYoung   \n",
       "6    UCy5KW4yrEfEiyZRX45Eoxkg            384913290      RepJohnYarmuth   \n",
       "7    UCg5ZIR5-82EbJiNeI1bqT-A             37007274         RepDonYoung   \n",
       "8    UCXJbUDLYX-wGIhRuN66hqZw            234469322   CongressmanWomack   \n",
       "9    UCP5QBhng_lHv-vJgE_h7lpA            234014087  repfredericawilson   \n",
       "..                        ...                  ...                 ...   \n",
       "913                       NaN  1082334352711790593                 NaN   \n",
       "914                       NaN  1081350574589833221                 NaN   \n",
       "915                       NaN  1080960924687704064                 NaN   \n",
       "916                       NaN  1083469084648505344                 NaN   \n",
       "922                       NaN  1276209702322438148                 NaN   \n",
       "\n",
       "        instagram instagram_id  ...  lis ballotpedia official_full  \\\n",
       "3    sentoddyoung          NaN  ...  NaN         NaN           NaN   \n",
       "6             NaN          NaN  ...  NaN         NaN           NaN   \n",
       "7             NaN          NaN  ...  NaN         NaN           NaN   \n",
       "8             NaN          NaN  ...  NaN         NaN           NaN   \n",
       "9       repwilson          NaN  ...  NaN         NaN           NaN   \n",
       "..            ...          ...  ...  ...         ...           ...   \n",
       "913           NaN          NaN  ...  NaN         NaN           NaN   \n",
       "914           NaN          NaN  ...  NaN         NaN           NaN   \n",
       "915           NaN          NaN  ...  NaN         NaN           NaN   \n",
       "916           NaN          NaN  ...  NaN         NaN           NaN   \n",
       "922           NaN          NaN  ...  NaN         NaN           NaN   \n",
       "\n",
       "    opensecrets  url  fec maplight state_rank caucus end-type  \n",
       "3           NaN  NaN  NaN      NaN        NaN    NaN      NaN  \n",
       "6           NaN  NaN  NaN      NaN        NaN    NaN      NaN  \n",
       "7           NaN  NaN  NaN      NaN        NaN    NaN      NaN  \n",
       "8           NaN  NaN  NaN      NaN        NaN    NaN      NaN  \n",
       "9           NaN  NaN  NaN      NaN        NaN    NaN      NaN  \n",
       "..          ...  ...  ...      ...        ...    ...      ...  \n",
       "913         NaN  NaN  NaN      NaN        NaN    NaN      NaN  \n",
       "914         NaN  NaN  NaN      NaN        NaN    NaN      NaN  \n",
       "915         NaN  NaN  NaN      NaN        NaN    NaN      NaN  \n",
       "916         NaN  NaN  NaN      NaN        NaN    NaN      NaN  \n",
       "922         NaN  NaN  NaN      NaN        NaN    NaN      NaN  \n",
       "\n",
       "[338 rows x 43 columns]"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['start'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioguide</th>\n",
       "      <th>govtrack</th>\n",
       "      <th>icpsr</th>\n",
       "      <th>wikipedia</th>\n",
       "      <th>wikidata</th>\n",
       "      <th>google_entity_id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>birthday</th>\n",
       "      <th>gender</th>\n",
       "      <th>...</th>\n",
       "      <th>cspan</th>\n",
       "      <th>votesmart</th>\n",
       "      <th>lis</th>\n",
       "      <th>ballotpedia</th>\n",
       "      <th>official_full</th>\n",
       "      <th>opensecrets</th>\n",
       "      <th>url</th>\n",
       "      <th>fec</th>\n",
       "      <th>maplight</th>\n",
       "      <th>state_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bioguide, govtrack, icpsr, wikipedia, wikidata, google_entity_id, first, last, birthday, gender, type, start, end, state, class, party, house_history, district, middle, nickname, suffix, bioguide_previous, house_history_alternate, thomas, cspan, votesmart, lis, ballotpedia, official_full, opensecrets, url, fec, maplight, state_rank]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 34 columns]"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_historical[df_historical['bioguide']=='Y000033']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioguide</th>\n",
       "      <th>thomas</th>\n",
       "      <th>lis</th>\n",
       "      <th>govtrack</th>\n",
       "      <th>opensecrets</th>\n",
       "      <th>votesmart</th>\n",
       "      <th>fec</th>\n",
       "      <th>cspan</th>\n",
       "      <th>wikipedia</th>\n",
       "      <th>house_history</th>\n",
       "      <th>...</th>\n",
       "      <th>district</th>\n",
       "      <th>party</th>\n",
       "      <th>url</th>\n",
       "      <th>class</th>\n",
       "      <th>state_rank</th>\n",
       "      <th>middle</th>\n",
       "      <th>nickname</th>\n",
       "      <th>suffix</th>\n",
       "      <th>caucus</th>\n",
       "      <th>end-type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bioguide, thomas, lis, govtrack, opensecrets, votesmart, fec, cspan, wikipedia, house_history, ballotpedia, maplight, icpsr, wikidata, google_entity_id, first, last, official_full, birthday, gender, type, start, end, state, district, party, url, class, state_rank, middle, nickname, suffix, caucus, end-type]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 34 columns]"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_current[df_current['bioguide']=='Y000033']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioguide</th>\n",
       "      <th>thomas</th>\n",
       "      <th>govtrack</th>\n",
       "      <th>twitter</th>\n",
       "      <th>facebook</th>\n",
       "      <th>youtube_id</th>\n",
       "      <th>twitter_id</th>\n",
       "      <th>youtube</th>\n",
       "      <th>instagram</th>\n",
       "      <th>instagram_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Y000033</td>\n",
       "      <td>'01256'</td>\n",
       "      <td>400440</td>\n",
       "      <td>RepDonYoung</td>\n",
       "      <td>RepDonYoung</td>\n",
       "      <td>UCg5ZIR5-82EbJiNeI1bqT-A</td>\n",
       "      <td>37007274</td>\n",
       "      <td>RepDonYoung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bioguide   thomas govtrack      twitter     facebook  \\\n",
       "5  Y000033  '01256'   400440  RepDonYoung  RepDonYoung   \n",
       "\n",
       "                 youtube_id twitter_id      youtube instagram instagram_id  \n",
       "5  UCg5ZIR5-82EbJiNeI1bqT-A   37007274  RepDonYoung       NaN          NaN  "
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_some[df_some['bioguide']=='Y000033']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
